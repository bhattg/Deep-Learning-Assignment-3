{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport os\nfrom tqdm import tqdm\nfrom pylab import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Hyper-parameters \ninput_size = 784\nhidden_size = 500\nnum_classes = 10\nnum_epochs = 5\nbatch_size = 100\nlearning_rate = 0.001\n\n# MNIST dataset \ntrain_dataset = torchvision.datasets.KMNIST(root='../../data',      \n                                           train=True, \n                                           transform=transforms.ToTensor(),\n                                           download=True)\n\ntest_dataset = torchvision.datasets.KMNIST(root='../../data', \n                                          train=False, \n                                          transform=transforms.ToTensor())\n\n# Data loader\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                           batch_size=batch_size, \n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n                                          batch_size=batch_size, \n                                          shuffle=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralNet(nn.Module):\n    def __init__(self,input_size,hidden_size,num_classes):\n        super(NeuralNet,self).__init__()\n        self.fc1=nn.Linear(input_size,hidden_size)\n        self.relu=nn.ReLU()\n        self.fc2=nn.Linear(hidden_size,num_classes)\n        \n    def forward(self,x):\n        out=self.fc1(x)\n        out=self.relu(out)\n        out=self.fc2(out)\n        return out\n    \nmodel=NeuralNet(input_size,hidden_size,num_classes).to(device)\n\n#loss and optimiser\ncriterion=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Kuzushiji(nn.Module):\n    def __init__(self):\n        super(Kuzushiji, self).__init__()\n        self.pad1 = nn.ZeroPad2d((2, 2))\n        \n        self.layer1 = nn.Sequential(\n        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(7, 7), stride=(1, 1), bias=False), \n        nn.BatchNorm2d(num_features=32),\n        nn.MaxPool2d(kernel_size=(2,2)),\n        nn.ReLU()\n        )\n    \n        \n        self.layer2 = nn.Sequential(\n        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5, 5), stride=(1, 1), bias=False), \n        nn.BatchNorm2d(num_features=64),\n        nn.ReLU()\n        )\n        \n        self.layer3 = nn.Sequential(\n        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=(1, 1), bias=False), \n        nn.BatchNorm2d(num_features=128),\n        nn.MaxPool2d(kernel_size=(2,2)),\n        nn.ReLU()\n        )\n        \n        self.fc1 = nn.Sequential(\n        nn.Linear(in_features=768, out_features=512),\n        nn.ReLU()\n        )\n        self.dropout1 = nn.Dropout(p=0.2)\n        \n        self.fc2 = nn.Sequential(\n        nn.Linear(in_features=512, out_features=10),\n        nn.Softmax()\n        )\n    def forward(self, x):\n        x = self.pad1(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = x.reshape(x.shape[0], -1)\n       # print(x.shape)\n        x = self.fc1(x)\n        x = self.dropout1(x)\n        out = self.fc2(x)\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model=Kuzushiji().to(device)\ncriterion=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(my_model.parameters(),lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\ntotal_step = len(train_loader)\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):  \n        # Move tensors to the configured device\n        images = images.reshape(-1, 1, 28,28).to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = my_model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 100 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.max(images[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normal Model Testing\n\nwith torch.no_grad():\n    correct=0\n    total=0\n    for images,labels in test_loader:\n        images=images.reshape(-1,1,28,28).to(device)\n        labels=labels.to(device)\n        outputs=my_model(images)\n        _,predicted=torch.max(outputs.data,1)\n        total+=labels.size(0)\n        correct+=(predicted==labels).sum().item()\n        \n    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in my_model.parameters():\n    param.requires_grad=False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Targeted FGSM attack \n\nepsilon=[0.0001,0.0003,0.001,0.003,0.1,0.3,0.5]\n\nfor value in epsilon:\n    for k in range(10):\n        l=[]\n        sign=[]\n        #actual=[]\n        for i,(images,labels) in enumerate(test_loader):\n            copyOf_images=images.reshape(-1,1,28,28).to(device)\n            copyOf_images.requires_grad=True\n            target_class=(labels+k)%10  #missing classifying it with 10 classes though it has to be correct at least once\n            target_class=target_class.to(device)\n\n            #forward pass\n            outputs=my_model(copyOf_images)\n            loss=criterion(outputs,target_class)\n\n            #backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            c=copyOf_images.grad.sign()\n            #actual.append((images,labels))\n            copyOf_images=copyOf_images-(value*c) \n            copyOf_images=torch.clamp(copyOf_images,0,1)\n            sign.append(c)\n            l.append((copyOf_images,labels))\n\n        with torch.no_grad():\n            correct=0\n            total=0\n            for images,labels in l:\n                images=images.reshape(-1,1,28,28).to(device)\n                labels=labels.to(device)\n                outputs=my_model(images)\n                _,predicted=torch.max(outputs.data,1)\n                total+=labels.size(0)\n                correct+=(predicted==labels).sum().item()\n            print(\"accuracy of the network on the 10000 test images for epsilon value {}:{} %\".format(value,100*correct/total)) \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Untargeted FGSM attack \n\nl=[]\nsign=[]\nactual=[]\nepsilon=[0.0001,0.0003,0.001,0.003,0.1,0.2,0.3,0.4,0.5]\n\nfor value in epsilon:\n   # for k in range(10):\n        l=[]\n        sign=[]\n        #actual=[]\n        for i,(images,labels) in enumerate(test_loader):\n            copyOf_images=images.reshape(-1,1,28,28).to(device)\n            copyOf_images.requires_grad=True\n            #target_class=(labels+k)%10  #missing classifying it with 10 classes though it has to be correct at least once\n            target_class=labels\n            target_class=target_class.to(device)\n            \n            #forward pass\n            outputs=my_model(copyOf_images)\n            loss=criterion(outputs,target_class)\n\n            #backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            c=copyOf_images.grad.sign()\n            #actual.append((images,labels))\n            copyOf_images=copyOf_images+(value*c) \n            copyOf_images=torch.clamp(copyOf_images,0,1)\n            sign.append(c)\n            l.append((copyOf_images,labels))\n\n        with torch.no_grad():\n            correct=0\n            total=0\n            for images,labels in l:\n                images=images.reshape(-1,1,28,28).to(device)\n                labels=labels.to(device)\n                outputs=my_model(images)\n                _,predicted=torch.max(outputs.data,1)\n                total+=labels.size(0)\n                correct+=(predicted==labels).sum().item()\n            print(\"accuracy of the network on the 10000 test images for epsilon value {}:{} %\".format(value,100*correct/total)) \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the accuracy after FGSM attack\n\nwith torch.no_grad():\n    correct=0\n    total=0\n    for images,labels in l:\n        images=images.reshape(-1,1,28,28).to(device)\n        labels=labels.to(device)\n        outputs=my_model(images)\n        _,predicted=torch.max(outputs.data,1)\n        total+=labels.size(0)\n        correct+=(predicted==labels).sum().item()\n    print(\"accuracy of the network on the 10000 test images:{} %\".format(100*correct/total))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Carlini Wagner Attack\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**> Following are just snippet tests,they don't mean anything as such\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"im,_=l[0]\nim=im.data.cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"old_im,_=actual[0]\nold_im=old_im.data.cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im=im.reshape(100,28,28)\nold_im=old_im.reshape(100,28,28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(old_im[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(im[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#these ae just snippet tests they don't mean anything now\nsubplot(1,2,1)\ntitle('adversarial example')\nimshow(im[2],cmap='gray')\nsubplot(1,2,2)\ntitle('actual sample')\nimshow(old_im[2],cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image1=torch.from_numpy(im[1])\nimg_t1=image1.reshape(-1,1,28,28).to(device)\noutputs=my_model(img_t1)\n_,predicted=torch.max(outputs.data,1)\nprint(predicted)\n\nimage2=torch.from_numpy(old_im[1])\nimg_t2=image2.reshape(-1,1,28,28).to(device)\noutputs=my_model(img_t2)\n_,predicted=torch.max(outputs.data,1)\nprint(predicted)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training a GAN **\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"g_input_size=10\ng_hidden_size=5\ng_output_size=\n\nd_input_size=\nd_hidden_size=10\nd_output_size=1\nminibatch_size=d_input_size \n\ngenerator_activation_function=torch.tanh\ndiscriminator_activation_function=torch.sigmoid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_generator_input_sampler():\n    return lambda n: torch.Tensor(np.random.normal(0,1,(g_input_size,1)))  #whatever is the size of the random input noise here 50*1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self,input_size,hidden_size,output_size,f):\n        super(Generator,self).__init__()\n        self.map1=nn.Linear(input_size,hidden_size)\n        self.map2=nn.Linear(hidden_size,hidden_size)\n        self.map3=nn.Linear(hidden_size,output_size)\n        self.f=f\n    def forward(self,x):\n        x=self.map1(x)\n        x=self.f(x)\n        x=self.map2(x)\n        x=self.f(x)\n        x=self.map3(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Discriminator(nn.Module):\n    def __init__(self,input_size,hidden_size,output_size,f):\n        super(Discriminator,self).__init__()\n        self.map1=nn.Linear(input_size,hidden_size)\n        self.map2=nn.Linear(hidden_size,hidden_size)\n        self.map3=nn.Linear(hidden_size,output_size)\n        self.f=f\n    def forward(self,x):\n        x=self.f(self.map1(x))\n        x=self.f(self.map2(x))\n        x=self.f(self.map3(x))\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G=Generator(input_size=g_input_size,\n           hidden_size=g_hidden_size,\n           output_size=g_output_size,\n           f=generator_activation_function)\n\nD=Discriminator(input_size=d_input_size,\n           hidden_size=d_hidden_size,\n           output_size=d_output_size,\n           f=discriminator_activation_function)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Number_epochs=50\nD_steps=5\n\nfor epoch in range(Number_epochs):\n    for d_index in range(D_steps):\n        #train D on real+fake\n        D\n        ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}