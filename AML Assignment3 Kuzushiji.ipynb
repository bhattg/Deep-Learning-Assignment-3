{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport os\nfrom tqdm import tqdm\nfrom pylab import *","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Hyper-parameters \ninput_size = 784\nhidden_size = 500\nnum_classes = 10\nnum_epochs = 15\nbatch_size = 100\nlearning_rate = 0.001\n\n# MNIST dataset \ntrain_dataset = torchvision.datasets.KMNIST(root='../../data',      \n                                           train=True, \n                                           transform=transforms.ToTensor(),\n                                           download=True)\n\ntest_dataset = torchvision.datasets.KMNIST(root='../../data', \n                                          train=False, \n                                          transform=transforms.ToTensor())\n\n# Data loader\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                           batch_size=batch_size, \n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n                                          batch_size=batch_size, \n                                          shuffle=False)\n\n","execution_count":2,"outputs":[{"output_type":"stream","text":"\r0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz to ../../data/KMNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"18169856it [00:08, 2174174.14it/s]                              \n","name":"stderr"},{"output_type":"stream","text":"Extracting ../../data/KMNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"\r0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz to ../../data/KMNIST/raw/train-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"32768it [00:00, 51029.28it/s]                            \n0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Extracting ../../data/KMNIST/raw/train-labels-idx1-ubyte.gz\nDownloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz to ../../data/KMNIST/raw/t10k-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"3047424it [00:02, 1191448.29it/s]                             \n0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Extracting ../../data/KMNIST/raw/t10k-images-idx3-ubyte.gz\nDownloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz to ../../data/KMNIST/raw/t10k-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"8192it [00:00, 16824.73it/s]            ","name":"stderr"},{"output_type":"stream","text":"Extracting ../../data/KMNIST/raw/t10k-labels-idx1-ubyte.gz\nProcessing...\nDone!\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(device)","execution_count":3,"outputs":[{"output_type":"stream","text":"cuda\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralNet(nn.Module):\n    def __init__(self,input_size,hidden_size,num_classes):\n        super(NeuralNet,self).__init__()\n        self.fc1=nn.Linear(input_size,hidden_size)\n        self.relu=nn.ReLU()\n        self.fc2=nn.Linear(hidden_size,num_classes)\n        \n    def forward(self,x):\n        out=self.fc1(x)\n        out=self.relu(out)\n        out=self.fc2(out)\n        return out\n    \nmodel=NeuralNet(input_size,hidden_size,num_classes).to(device)\n\n#loss and optimiser\ncriterion=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Kuzushiji(nn.Module):\n    def __init__(self):\n        super(Kuzushiji, self).__init__()\n        self.pad1 = nn.ZeroPad2d((2, 2))\n        \n        self.layer1 = nn.Sequential(\n        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(7, 7), stride=(1, 1), bias=False), \n        nn.BatchNorm2d(num_features=32),\n        nn.MaxPool2d(kernel_size=(2,2)),\n        nn.ReLU()\n        )\n    \n        \n        self.layer2 = nn.Sequential(\n        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5, 5), stride=(1, 1), bias=False), \n        nn.BatchNorm2d(num_features=64),\n        nn.ReLU()\n        )\n        \n        self.layer3 = nn.Sequential(\n        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=(1, 1), bias=False), \n        nn.BatchNorm2d(num_features=128),\n        nn.MaxPool2d(kernel_size=(2,2)),\n        nn.ReLU()\n        )\n        \n        self.fc1 = nn.Sequential(\n        nn.Linear(in_features=768, out_features=512),\n        nn.ReLU()\n        )\n        self.dropout1 = nn.Dropout(p=0.2)\n        \n        self.fc2 = nn.Sequential(\n        nn.Linear(in_features=512, out_features=10),\n        nn.Softmax()\n        )\n        \n    def forward(self, x):\n        x = self.pad1(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = x.reshape(x.shape[0], -1)\n       # print(x.shape)\n        x = self.fc1(x)\n        x = self.dropout1(x)\n        out = self.fc2(x)\n        \n        return out,x","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model=Kuzushiji().to(device)\ncriterion=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(my_model.parameters(),lr=learning_rate)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\ntotal_step = len(train_loader)\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):  \n        # Move tensors to the configured device\n        images = images.reshape(-1, 1, 28,28).to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = my_model(images)[0]\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 100 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))","execution_count":6,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Epoch [1/15], Step [100/600], Loss: 1.5834\nEpoch [1/15], Step [200/600], Loss: 1.6239\nEpoch [1/15], Step [300/600], Loss: 1.5410\nEpoch [1/15], Step [400/600], Loss: 1.5461\nEpoch [1/15], Step [500/600], Loss: 1.4817\nEpoch [1/15], Step [600/600], Loss: 1.5728\nEpoch [2/15], Step [100/600], Loss: 1.5398\nEpoch [2/15], Step [200/600], Loss: 1.4964\nEpoch [2/15], Step [300/600], Loss: 1.5125\nEpoch [2/15], Step [400/600], Loss: 1.5221\nEpoch [2/15], Step [500/600], Loss: 1.4863\nEpoch [2/15], Step [600/600], Loss: 1.4723\nEpoch [3/15], Step [100/600], Loss: 1.5254\nEpoch [3/15], Step [200/600], Loss: 1.5156\nEpoch [3/15], Step [300/600], Loss: 1.4916\nEpoch [3/15], Step [400/600], Loss: 1.4741\nEpoch [3/15], Step [500/600], Loss: 1.4915\nEpoch [3/15], Step [600/600], Loss: 1.4841\nEpoch [4/15], Step [100/600], Loss: 1.4870\nEpoch [4/15], Step [200/600], Loss: 1.4839\nEpoch [4/15], Step [300/600], Loss: 1.4929\nEpoch [4/15], Step [400/600], Loss: 1.4893\nEpoch [4/15], Step [500/600], Loss: 1.4903\nEpoch [4/15], Step [600/600], Loss: 1.4808\nEpoch [5/15], Step [100/600], Loss: 1.4931\nEpoch [5/15], Step [200/600], Loss: 1.5214\nEpoch [5/15], Step [300/600], Loss: 1.4944\nEpoch [5/15], Step [400/600], Loss: 1.4748\nEpoch [5/15], Step [500/600], Loss: 1.4713\nEpoch [5/15], Step [600/600], Loss: 1.4626\nEpoch [6/15], Step [100/600], Loss: 1.4878\nEpoch [6/15], Step [200/600], Loss: 1.4871\nEpoch [6/15], Step [300/600], Loss: 1.4939\nEpoch [6/15], Step [400/600], Loss: 1.4927\nEpoch [6/15], Step [500/600], Loss: 1.4709\nEpoch [6/15], Step [600/600], Loss: 1.5170\nEpoch [7/15], Step [100/600], Loss: 1.4781\nEpoch [7/15], Step [200/600], Loss: 1.4742\nEpoch [7/15], Step [300/600], Loss: 1.4807\nEpoch [7/15], Step [400/600], Loss: 1.4812\nEpoch [7/15], Step [500/600], Loss: 1.4932\nEpoch [7/15], Step [600/600], Loss: 1.4612\nEpoch [8/15], Step [100/600], Loss: 1.4813\nEpoch [8/15], Step [200/600], Loss: 1.4719\nEpoch [8/15], Step [300/600], Loss: 1.4967\nEpoch [8/15], Step [400/600], Loss: 1.4821\nEpoch [8/15], Step [500/600], Loss: 1.4714\nEpoch [8/15], Step [600/600], Loss: 1.4804\nEpoch [9/15], Step [100/600], Loss: 1.4917\nEpoch [9/15], Step [200/600], Loss: 1.4812\nEpoch [9/15], Step [300/600], Loss: 1.4913\nEpoch [9/15], Step [400/600], Loss: 1.4653\nEpoch [9/15], Step [500/600], Loss: 1.4811\nEpoch [9/15], Step [600/600], Loss: 1.4751\nEpoch [10/15], Step [100/600], Loss: 1.4727\nEpoch [10/15], Step [200/600], Loss: 1.4738\nEpoch [10/15], Step [300/600], Loss: 1.4670\nEpoch [10/15], Step [400/600], Loss: 1.4808\nEpoch [10/15], Step [500/600], Loss: 1.4711\nEpoch [10/15], Step [600/600], Loss: 1.4933\nEpoch [11/15], Step [100/600], Loss: 1.4932\nEpoch [11/15], Step [200/600], Loss: 1.4885\nEpoch [11/15], Step [300/600], Loss: 1.4612\nEpoch [11/15], Step [400/600], Loss: 1.4716\nEpoch [11/15], Step [500/600], Loss: 1.4720\nEpoch [11/15], Step [600/600], Loss: 1.4729\nEpoch [12/15], Step [100/600], Loss: 1.4793\nEpoch [12/15], Step [200/600], Loss: 1.4818\nEpoch [12/15], Step [300/600], Loss: 1.4769\nEpoch [12/15], Step [400/600], Loss: 1.4612\nEpoch [12/15], Step [500/600], Loss: 1.4671\nEpoch [12/15], Step [600/600], Loss: 1.4948\nEpoch [13/15], Step [100/600], Loss: 1.4812\nEpoch [13/15], Step [200/600], Loss: 1.4730\nEpoch [13/15], Step [300/600], Loss: 1.4810\nEpoch [13/15], Step [400/600], Loss: 1.4710\nEpoch [13/15], Step [500/600], Loss: 1.4712\nEpoch [13/15], Step [600/600], Loss: 1.4617\nEpoch [14/15], Step [100/600], Loss: 1.4935\nEpoch [14/15], Step [200/600], Loss: 1.4712\nEpoch [14/15], Step [300/600], Loss: 1.4989\nEpoch [14/15], Step [400/600], Loss: 1.4798\nEpoch [14/15], Step [500/600], Loss: 1.4720\nEpoch [14/15], Step [600/600], Loss: 1.4929\nEpoch [15/15], Step [100/600], Loss: 1.4858\nEpoch [15/15], Step [200/600], Loss: 1.4612\nEpoch [15/15], Step [300/600], Loss: 1.4673\nEpoch [15/15], Step [400/600], Loss: 1.4612\nEpoch [15/15], Step [500/600], Loss: 1.4612\nEpoch [15/15], Step [600/600], Loss: 1.4901\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normal Model Testing\nwith torch.no_grad():\n    correct=0\n    total=0\n    for images,labels in test_loader:\n        images=images.reshape(-1,1,28,28).to(device)\n        labels=labels.to(device)\n        outputs=my_model(images)[0]\n        _,predicted=torch.max(outputs.data,1)\n        total+=labels.size(0)\n        correct+=(predicted==labels).sum().item()\n        \n    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))","execution_count":9,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the 10000 test images: 93.96 %\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# FGSM Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in my_model.parameters():\n    param.requires_grad=False","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Targeted FGSM attack "},{"metadata":{"trusted":true},"cell_type":"code","source":"#targeted fgsm \n\n#epsilon=[0.0001,0.0003,0.001,0.003,0.1,0.2,0.3,0.4,0.5]\npred_list=[]\nepsilon=[0.3]\n\nfor value in epsilon:\n    pred_val_list=[]\n    for k in range(2,3):\n        l_tfgsm=[]\n        sign=[]\n        #actual=[]\n        for i,(images,labels) in enumerate(test_loader):\n            copyOf_images=images.clone().detach()\n            copyOf_images=copyOf_images.reshape(-1,1,28,28).to(device)\n            copyOf_images.requires_grad=True\n            target_class=(labels+k)%10  #missing classifying it with 10 classes though it has to be correct at least once\n            target_class=target_class.to(device)\n\n            #forward pass\n            outputs=my_model(copyOf_images)[0]\n            loss=criterion(outputs,target_class)\n\n            #backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            c=copyOf_images.grad.sign()\n            #actual.append((images,labels))\n            copyOf_images=copyOf_images-(value*c) \n            copyOf_images=torch.clamp(copyOf_images,0,1)\n            sign.append(c)\n            l_tfgsm.append((copyOf_images,images,labels))\n\n        with torch.no_grad():\n            correct=0\n            total=0\n            for images,trueimages,labels in l_tfgsm:\n                images=images.reshape(-1,1,28,28).to(device)\n                labels=labels.to(device)\n                outputs=my_model(images)[0]\n                _,predicted=torch.max(outputs.data,1)\n                total+=labels.size(0)\n                correct+=(predicted==labels).sum().item()\n            pred_val_list.append(100*correct/total)\n            print(\"accuracy of the network on the 10000 test images for epsilon value {}:{} %\".format(value,100*correct/total)) \n    pred_list.append(pred_val_list)","execution_count":8,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"accuracy of the network on the 10000 test images for epsilon value 0.3:78.53 %\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pred_list)\n\nimport matplotlib.pyplot as plt\n\nmake_list=[]\nepsilon=[0.0001,0.0003,0.001,0.003,0.1,0.2,0.3,0.4,0.5]\n\nfor k in pred_list:\n    make_list.append(k[2])\nplt.plot(epsilon,make_list)\nplt.xlabel(\"Epsilon Value\")\nplt.ylabel(\"Accuracy(in %)\")\nplt.title(\"Targeted FGSM on Kuzushiji where Target labels =(True label+2)%10\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Untargeted FGSM attack \nl=[]\nsign=[]\nactual=[]\nepsilon=[0.0001,0.0003,0.001,0.003,0.1,0.2,0.3,0.4,0.5]\n\nfor value in epsilon:\n   # for k in range(10):\n        l=[]\n        sign=[]\n        #actual=[]\n        for i,(images,labels) in enumerate(test_loader):\n            copyOf_images=images.clone().detach()\n            copyOf_images=copyOf_images.reshape(-1,1,28,28).to(device)\n            copyOf_images.requires_grad=True\n            #target_class=(labels+k)%10  #missing classifying it with 10 classes though it has to be correct at least once\n            target_class=labels\n            target_class=target_class.to(device)\n            \n            #forward pass\n            outputs=my_model(copyOf_images)\n            loss=criterion(outputs,target_class)\n\n            #backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            c=copyOf_images.grad.sign()\n            #actual.append((images,labels))\n            copyOf_images=copyOf_images+(value*c) \n            copyOf_images=torch.clamp(copyOf_images,0,1)\n            sign.append(c)\n            l.append((copyOf_images,labels))\n\n        with torch.no_grad():\n            correct=0\n            total=0\n            for images,labels in l:\n                images=images.reshape(-1,1,28,28).to(device)\n                labels=labels.to(device)\n                outputs=my_model(images)\n                _,predicted=torch.max(outputs.data,1)\n                total+=labels.size(0)\n                correct+=(predicted==labels).sum().item()\n            print(\"accuracy of the network on the 10000 test images for epsilon value {}:{} %\".format(value,100*correct/total)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the accuracy after FGSM attack\n\nwith torch.no_grad():\n    correct=0\n    total=0\n    for images,labels in l:\n        images=images.reshape(-1,1,28,28).to(device)\n        labels=labels.to(device)\n        outputs=my_model(images)\n        _,predicted=torch.max(outputs.data,1)\n        total+=labels.size(0)\n        correct+=(predicted==labels).sum().item()\n    print(\"accuracy of the network on the 10000 test images:{} %\".format(100*correct/total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_var(x, requires_grad=False, volatile=False):\n    \"\"\"\n    Varialbe type that automatically choose cpu or cuda\n    \"\"\"\n    if torch.cuda.is_available():\n        x = x.cuda()\n    return Variable(x, requires_grad=requires_grad, volatile=volatile)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PGD Attack \n\nclass LinfPGDAttack(nn.Module):\n    \n    def __init__(self,model=None,epsilon=0.3,k=40,a=0.01,random_start=True):\n        super(LinfPGDAttack, self).__init__()\n        self.model=model\n        self.epsilon=epsilon\n        self.k=k\n        self.a=a\n        self.randn=random_start\n        self.loss_fn=nn.CrossEntropyLoss() \n    \n    def perturb(self,X_nat,y):\n        \n        if self.randn:\n            X=X_nat+np.random.uniform(-self.epsilon,self.epsilon,X_nat.shape).astype('float32')\n        else:\n            X=np.copy(X_nat)\n        \n        for i in range(self.k):\n            X_var=to_var(torch.from_numpy(X),requires_grad=True)\n            y_var=to_var(torch.LongTensor(y))\n            \n            scores=self.model(X_var)[0]\n            loss=self.loss_fn(scores,y_var)\n            loss.backward()\n            grad=X_var.grad.data.cpu().numpy()\n            \n            X-=self.a*np.sign(grad)\n            \n            X=np.clip(X,X_nat-self.epsilon,X_nat+self.epsilon)\n            X=np.clip(X,0,1)\n        \n        return X","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.autograd import Variable\n\nl_pgd=[]\n#perturbed_images=[]\n#epsilon=[0.001,0.003,0.01,0.03,0.1,0.2,0.3,0.4,0.5]\ntmp_list=[]\nepsilon=[0.4]\nfor value in epsilon:\n    for i,(images,labels) in enumerate(test_loader):       \n        PGDobj=LinfPGDAttack(model=my_model,random_start=False,epsilon=value)\n        target=(labels+3)%10  #generating the target\n        Changed_Images=PGDobj.perturb(images.numpy(),target.numpy())\n        if np.array_equal(Changed_Images,images.numpy()):\n            print(\"No change\")\n            break        \n        l_pgd.append((torch.from_numpy(Changed_Images),images,labels))\n        if(i%50==0):\n            print(\"Now adding changed images in {}th iteration\".format(i))\n\n    with torch.no_grad():\n        correct=0\n        total=0\n        for images,trueimage,labels in l_pgd:\n            images=images.reshape(-1,1,28,28).to(device)\n            labels=labels.to(device)\n            outputs=my_model(images)[0]\n            _,predicted=torch.max(outputs.data,1)\n            total+=labels.size(0)\n            correct+=(predicted==labels).sum().item()\n        tmp_list.append(100*correct/total)\n        print(\"accuracy of the network on the 10000 test images:{} %\".format(100*correct/total))","execution_count":68,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Now adding changed images in 0th iteration\nNow adding changed images in 50th iteration\naccuracy of the network on the 10000 test images:88.86 %\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.autograd import Variable\n\nl=[]\n#perturbed_images=[]\na=[0.001,0.003,0.01,0.03,0.1,0.2,0.3,0.4,0.5]\ntmp_list=[]\n\nfor value in epsilon:\n    for i,(images,labels) in enumerate(test_loader):       \n        PGDobj=LinfPGDAttack(model=my_model,random_start=False,a=value)\n        target=(labels+1)%10  #generating the target\n        Changed_Images=PGDobj.perturb(images.numpy(),target.numpy())\n        if np.array_equal(Changed_Images,images.numpy()):\n            print(\"No change\")\n            break        \n        l.append((torch.from_numpy(Changed_Images),labels))\n        if(i%50==0):\n            print(\"Now adding changed images in {}th iteration\".format(i))\n\n    with torch.no_grad():\n        correct=0\n        total=0\n        for images,labels in l:\n            images=images.reshape(-1,1,28,28).to(device)\n            labels=labels.to(device)\n            outputs=my_model(images)\n            _,predicted=torch.max(outputs.data,1)\n            total+=labels.size(0)\n            correct+=(predicted==labels).sum().item()\n        tmp_list.append(100*correct/total)\n        print(\"accuracy of the network on the 10000 test images:{} %\".format(100*correct/total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(a,tmp_list)\nplt.title(\"Targeted PGD over Kuzushiji\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Value of One Step of Gradient Descent\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the accuracy after FGSM attack\nwith torch.no_grad():\n    correct=0\n    total=0\n    for images,labels in l:\n        images=images.reshape(-1,1,28,28).to(device)\n        labels=labels.to(device)\n        outputs=my_model(images)\n        _,predicted=torch.max(outputs.data,1)\n        total+=labels.size(0)\n        correct+=(predicted==labels).sum().item()\n    \n    print(\"accuracy of the network on the 10000 test images:{} %\".format(100*correct/total))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Carlini Wagner Attack"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CW-L2 Attack\n# Based on the paper, i.e. not exact same version of the code on https://github.com/carlini/nn_robust_attacks\n# (1) Binary search method for c, (2) Optimization on tanh space, (3) Choosing method best l2 adversaries is NOT IN THIS CODE.\ndef cw_l2_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, max_iter=200, learning_rate=0.01) :\n\n    images = images.to(device)     \n    labels = labels.to(device)\n\n    # Define f-function\n    def f(x) :\n\n        outputs = model(x)[1]  #taking penultimate layer in this case rather than the softmax layer\n        one_hot_labels = torch.eye(len(outputs[0]))[labels].to(device)\n\n        i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)\n        j = torch.masked_select(outputs, one_hot_labels.byte())\n        \n        # If targeted, optimize for making the other class most likely \n        if targeted :\n            return torch.clamp(i-j, min=-kappa)\n        \n        # If untargeted, optimize for making the other class most likely \n        else :\n            return torch.clamp(j-i, min=-kappa)\n    \n    w = torch.zeros_like(images, requires_grad=True).to(device)\n\n    optimizer = torch.optim.Adam([w], lr=learning_rate)\n\n    prev = 1e10\n    \n    for step in tqdm(range(max_iter)) :\n\n        a = 1/2*(nn.Tanh()(w) + 1)\n\n        loss1 = nn.MSELoss(reduction='sum')(a, images)\n        loss2 = torch.sum(c*f(a))\n\n        cost = loss1 + loss2\n\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n\n        # Early Stop when loss does not converge.\n        if step % (max_iter//10) == 0 :\n            if cost > prev :\n                print('Attack Stopped due to CONVERGENCE....')\n                return a\n            prev = cost\n        \n        print('- Learning Progress : %2.2f %%        ' %((step+1)/max_iter*100), end='\\r')\n\n    attack_images = 1/2*(nn.Tanh()(w) + 1)\n\n    return attack_images","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Attack Image & Predicted Label\")\n\n#kappa=[0.01,0.03,1,3,5,7,9]\n#options=[0.01,0.03,0.1,0.2,0.3,0.4,0.5]\noptions=[0.5]\ntmp_list=[]\nl=[]\nfor value in options:\n    correct = 0\n    total = 0\n    for i,(images, labels) in enumerate(test_loader):\n        if (i<20):\n            #target=(labels+2)%10 \n            images_ = cw_l2_attack(my_model, images, labels, targeted=True,c=value,kappa=5)\n            #images = cw_l2_attack(my_model, images, target, c=0.1)\n            labels = labels.to(device)\n            outputs = my_model(images_)[0]\n            \n            _, pre = torch.max(outputs.data, 1)\n            l.append((images_,images,labels))\n            total+=labels.size(0)\n            correct += (pre == labels).sum().item()\n\n            #imshow(torchvision.utils.make_grid(images.cpu().data, normalize=True), [normal_data.classes[i] for i in pre])\n    tmp_list.append(100*float(correct)/total)\n    print('Accuracy of test text: %f %%' % (100 * float(correct) / total))","execution_count":49,"outputs":[{"output_type":"stream","text":"  0%|          | 0/200 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n 12%|█▏        | 23/200 [00:00<00:00, 220.97it/s]","name":"stderr"},{"output_type":"stream","text":"Attack Image & Predicted Label\n- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 36%|███▌      | 71/200 [00:00<00:00, 225.42it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 59%|█████▉    | 118/200 [00:00<00:00, 226.02it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 83%|████████▎ | 166/200 [00:00<00:00, 230.30it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 229.86it/s]\n  0%|          | 0/200 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 24%|██▍       | 48/200 [00:00<00:00, 236.38it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 96/200 [00:00<00:00, 234.45it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 72%|███████▏  | 143/200 [00:00<00:00, 232.26it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 233.47it/s]\n  0%|          | 0/200 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 24%|██▎       | 47/200 [00:00<00:00, 233.06it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 95/200 [00:00<00:00, 235.52it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 72%|███████▏  | 143/200 [00:00<00:00, 234.84it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 96%|█████████▌| 191/200 [00:00<00:00, 234.56it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 234.24it/s]\n 12%|█▎        | 25/200 [00:00<00:00, 240.11it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 36%|███▋      | 73/200 [00:00<00:00, 237.57it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 60%|██████    | 120/200 [00:00<00:00, 235.13it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 84%|████████▍ | 168/200 [00:00<00:00, 235.64it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 234.76it/s]\n 12%|█▏        | 24/200 [00:00<00:00, 238.74it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 36%|███▌      | 72/200 [00:00<00:00, 238.01it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 60%|██████    | 120/200 [00:00<00:00, 235.90it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 84%|████████▍ | 168/200 [00:00<00:00, 235.73it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 235.42it/s]\n  0%|          | 0/200 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 24%|██▍       | 48/200 [00:00<00:00, 235.78it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 96/200 [00:00<00:00, 235.21it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 72%|███████▏  | 144/200 [00:00<00:00, 233.68it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 234.23it/s]\n  0%|          | 0/200 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 24%|██▍       | 48/200 [00:00<00:00, 234.47it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 96/200 [00:00<00:00, 234.96it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 72%|███████▏  | 144/200 [00:00<00:00, 235.31it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 233.67it/s]\n  0%|          | 0/200 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 24%|██▍       | 48/200 [00:00<00:00, 235.52it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 96/200 [00:00<00:00, 236.21it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 72%|███████▏  | 144/200 [00:00<00:00, 236.68it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 96%|█████████▌| 192/200 [00:00<00:00, 235.04it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 234.42it/s]\n 12%|█▏        | 24/200 [00:00<00:00, 239.51it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 36%|███▌      | 72/200 [00:00<00:00, 237.62it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 60%|██████    | 120/200 [00:00<00:00, 236.90it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 84%|████████▍ | 168/200 [00:00<00:00, 237.18it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 236.43it/s]\n 12%|█▏        | 24/200 [00:00<00:00, 230.47it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 34%|███▍      | 69/200 [00:00<00:00, 226.82it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 58%|█████▊    | 117/200 [00:00<00:00, 230.89it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 82%|████████▎ | 165/200 [00:00<00:00, 233.03it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 231.44it/s]\n  0%|          | 0/200 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 24%|██▍       | 48/200 [00:00<00:00, 235.83it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        ","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 95/200 [00:00<00:00, 233.50it/s]","name":"stderr"},{"output_type":"stream","text":"\r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 70%|███████   | 140/200 [00:00<00:00, 225.82it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 230.81it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r","name":"stdout"},{"output_type":"stream","text":"\n 24%|██▍       | 48/200 [00:00<00:00, 236.94it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 96/200 [00:00<00:00, 234.86it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 72%|███████▏  | 144/200 [00:00<00:00, 234.86it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 96%|█████████▌| 191/200 [00:00<00:00, 232.33it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 232.57it/s]\n 12%|█▏        | 23/200 [00:00<00:00, 225.41it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 36%|███▌      | 71/200 [00:00<00:00, 229.91it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 59%|█████▉    | 118/200 [00:00<00:00, 230.07it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 83%|████████▎ | 166/200 [00:00<00:00, 232.42it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 231.15it/s]\n  0%|          | 0/200 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 24%|██▎       | 47/200 [00:00<00:00, 232.55it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 95/200 [00:00<00:00, 234.54it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 72%|███████▏  | 143/200 [00:00<00:00, 234.36it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 233.94it/s]\n  0%|          | 0/200 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 24%|██▍       | 48/200 [00:00<00:00, 234.99it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 96/200 [00:00<00:00, 234.63it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 72%|███████▏  | 144/200 [00:00<00:00, 235.10it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 232.97it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r","name":"stdout"},{"output_type":"stream","text":"\n 24%|██▍       | 48/200 [00:00<00:00, 236.61it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 96/200 [00:00<00:00, 236.25it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 72%|███████▏  | 144/200 [00:00<00:00, 235.89it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 96%|█████████▌| 192/200 [00:00<00:00, 235.00it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 234.52it/s]\n 12%|█▏        | 24/200 [00:00<00:00, 235.36it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 36%|███▌      | 72/200 [00:00<00:00, 235.91it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 60%|█████▉    | 119/200 [00:00<00:00, 234.32it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 84%|████████▎ | 167/200 [00:00<00:00, 234.39it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 233.92it/s]\n 12%|█▏        | 23/200 [00:00<00:00, 227.40it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 35%|███▌      | 70/200 [00:00<00:00, 230.53it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 59%|█████▉    | 118/200 [00:00<00:00, 233.07it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r","name":"stdout"},{"output_type":"stream","text":" 83%|████████▎ | 166/200 [00:00<00:00, 234.64it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 233.85it/s]\n  0%|          | 0/200 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 24%|██▍       | 48/200 [00:00<00:00, 236.30it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 95/200 [00:00<00:00, 234.75it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 71%|███████   | 142/200 [00:00<00:00, 233.11it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 233.80it/s]\n  0%|          | 0/200 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r- Learning Progress : 97.50 %        \r- Learning Progress : 98.00 %        \r- Learning Progress : 98.50 %        \r- Learning Progress : 99.00 %        \r- Learning Progress : 99.50 %        \r- Learning Progress : 100.00 %        \r- Learning Progress : 0.50 %        \r- Learning Progress : 1.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 24%|██▍       | 48/200 [00:00<00:00, 237.71it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 1.50 %        \r- Learning Progress : 2.00 %        \r- Learning Progress : 2.50 %        \r- Learning Progress : 3.00 %        \r- Learning Progress : 3.50 %        \r- Learning Progress : 4.00 %        \r- Learning Progress : 4.50 %        \r- Learning Progress : 5.00 %        \r- Learning Progress : 5.50 %        \r- Learning Progress : 6.00 %        \r- Learning Progress : 6.50 %        \r- Learning Progress : 7.00 %        \r- Learning Progress : 7.50 %        \r- Learning Progress : 8.00 %        \r- Learning Progress : 8.50 %        \r- Learning Progress : 9.00 %        \r- Learning Progress : 9.50 %        \r- Learning Progress : 10.00 %        \r- Learning Progress : 10.50 %        \r- Learning Progress : 11.00 %        \r- Learning Progress : 11.50 %        \r- Learning Progress : 12.00 %        \r- Learning Progress : 12.50 %        \r- Learning Progress : 13.00 %        \r- Learning Progress : 13.50 %        \r- Learning Progress : 14.00 %        \r- Learning Progress : 14.50 %        \r- Learning Progress : 15.00 %        \r- Learning Progress : 15.50 %        \r- Learning Progress : 16.00 %        \r- Learning Progress : 16.50 %        \r- Learning Progress : 17.00 %        \r- Learning Progress : 17.50 %        \r- Learning Progress : 18.00 %        \r- Learning Progress : 18.50 %        \r- Learning Progress : 19.00 %        \r- Learning Progress : 19.50 %        \r- Learning Progress : 20.00 %        \r- Learning Progress : 20.50 %        \r- Learning Progress : 21.00 %        \r- Learning Progress : 21.50 %        \r- Learning Progress : 22.00 %        \r- Learning Progress : 22.50 %        \r- Learning Progress : 23.00 %        \r- Learning Progress : 23.50 %        \r- Learning Progress : 24.00 %        \r- Learning Progress : 24.50 %        \r- Learning Progress : 25.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 48%|████▊     | 96/200 [00:00<00:00, 235.84it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 25.50 %        \r- Learning Progress : 26.00 %        \r- Learning Progress : 26.50 %        \r- Learning Progress : 27.00 %        \r- Learning Progress : 27.50 %        \r- Learning Progress : 28.00 %        \r- Learning Progress : 28.50 %        \r- Learning Progress : 29.00 %        \r- Learning Progress : 29.50 %        \r- Learning Progress : 30.00 %        \r- Learning Progress : 30.50 %        \r- Learning Progress : 31.00 %        \r- Learning Progress : 31.50 %        \r- Learning Progress : 32.00 %        \r- Learning Progress : 32.50 %        \r- Learning Progress : 33.00 %        \r- Learning Progress : 33.50 %        \r- Learning Progress : 34.00 %        \r- Learning Progress : 34.50 %        \r- Learning Progress : 35.00 %        \r- Learning Progress : 35.50 %        \r- Learning Progress : 36.00 %        \r- Learning Progress : 36.50 %        \r- Learning Progress : 37.00 %        \r- Learning Progress : 37.50 %        \r- Learning Progress : 38.00 %        \r- Learning Progress : 38.50 %        \r- Learning Progress : 39.00 %        \r- Learning Progress : 39.50 %        \r- Learning Progress : 40.00 %        \r- Learning Progress : 40.50 %        \r- Learning Progress : 41.00 %        \r- Learning Progress : 41.50 %        \r- Learning Progress : 42.00 %        \r- Learning Progress : 42.50 %        \r- Learning Progress : 43.00 %        \r- Learning Progress : 43.50 %        \r- Learning Progress : 44.00 %        \r- Learning Progress : 44.50 %        \r- Learning Progress : 45.00 %        \r- Learning Progress : 45.50 %        \r- Learning Progress : 46.00 %        \r- Learning Progress : 46.50 %        \r- Learning Progress : 47.00 %        \r- Learning Progress : 47.50 %        \r- Learning Progress : 48.00 %        \r- Learning Progress : 48.50 %        \r- Learning Progress : 49.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 72%|███████▏  | 144/200 [00:00<00:00, 235.49it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 49.50 %        \r- Learning Progress : 50.00 %        \r- Learning Progress : 50.50 %        \r- Learning Progress : 51.00 %        \r- Learning Progress : 51.50 %        \r- Learning Progress : 52.00 %        \r- Learning Progress : 52.50 %        \r- Learning Progress : 53.00 %        \r- Learning Progress : 53.50 %        \r- Learning Progress : 54.00 %        \r- Learning Progress : 54.50 %        \r- Learning Progress : 55.00 %        \r- Learning Progress : 55.50 %        \r- Learning Progress : 56.00 %        \r- Learning Progress : 56.50 %        \r- Learning Progress : 57.00 %        \r- Learning Progress : 57.50 %        \r- Learning Progress : 58.00 %        \r- Learning Progress : 58.50 %        \r- Learning Progress : 59.00 %        \r- Learning Progress : 59.50 %        \r- Learning Progress : 60.00 %        \r- Learning Progress : 60.50 %        \r- Learning Progress : 61.00 %        \r- Learning Progress : 61.50 %        \r- Learning Progress : 62.00 %        \r- Learning Progress : 62.50 %        \r- Learning Progress : 63.00 %        \r- Learning Progress : 63.50 %        \r- Learning Progress : 64.00 %        \r- Learning Progress : 64.50 %        \r- Learning Progress : 65.00 %        \r- Learning Progress : 65.50 %        \r- Learning Progress : 66.00 %        \r- Learning Progress : 66.50 %        \r- Learning Progress : 67.00 %        \r- Learning Progress : 67.50 %        \r- Learning Progress : 68.00 %        \r- Learning Progress : 68.50 %        \r- Learning Progress : 69.00 %        \r- Learning Progress : 69.50 %        \r- Learning Progress : 70.00 %        \r- Learning Progress : 70.50 %        \r- Learning Progress : 71.00 %        \r- Learning Progress : 71.50 %        \r- Learning Progress : 72.00 %        \r- Learning Progress : 72.50 %        \r- Learning Progress : 73.00 %        \r","name":"stdout"},{"output_type":"stream","text":" 96%|█████████▌| 192/200 [00:00<00:00, 234.77it/s]","name":"stderr"},{"output_type":"stream","text":"- Learning Progress : 73.50 %        \r- Learning Progress : 74.00 %        \r- Learning Progress : 74.50 %        \r- Learning Progress : 75.00 %        \r- Learning Progress : 75.50 %        \r- Learning Progress : 76.00 %        \r- Learning Progress : 76.50 %        \r- Learning Progress : 77.00 %        \r- Learning Progress : 77.50 %        \r- Learning Progress : 78.00 %        \r- Learning Progress : 78.50 %        \r- Learning Progress : 79.00 %        \r- Learning Progress : 79.50 %        \r- Learning Progress : 80.00 %        \r- Learning Progress : 80.50 %        \r- Learning Progress : 81.00 %        \r- Learning Progress : 81.50 %        \r- Learning Progress : 82.00 %        \r- Learning Progress : 82.50 %        \r- Learning Progress : 83.00 %        \r- Learning Progress : 83.50 %        \r- Learning Progress : 84.00 %        \r- Learning Progress : 84.50 %        \r- Learning Progress : 85.00 %        \r- Learning Progress : 85.50 %        \r- Learning Progress : 86.00 %        \r- Learning Progress : 86.50 %        \r- Learning Progress : 87.00 %        \r- Learning Progress : 87.50 %        \r- Learning Progress : 88.00 %        \r- Learning Progress : 88.50 %        \r- Learning Progress : 89.00 %        \r- Learning Progress : 89.50 %        \r- Learning Progress : 90.00 %        \r- Learning Progress : 90.50 %        \r- Learning Progress : 91.00 %        \r- Learning Progress : 91.50 %        \r- Learning Progress : 92.00 %        \r- Learning Progress : 92.50 %        \r- Learning Progress : 93.00 %        \r- Learning Progress : 93.50 %        \r- Learning Progress : 94.00 %        \r- Learning Progress : 94.50 %        \r- Learning Progress : 95.00 %        \r- Learning Progress : 95.50 %        \r- Learning Progress : 96.00 %        \r- Learning Progress : 96.50 %        \r- Learning Progress : 97.00 %        \r","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 200/200 [00:00<00:00, 234.50it/s]\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of test text: 73.300000 %    \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.asarray(l).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tmp_list)\n\nimport matplotlib.pyplot as plt\nplt.title(\"Targeted L2 Carlini Wagner Attack on Kuzushiji\")\nplt.xlabel(\"Different k values keeping c=0.3,learning_rate=0.01,num_iters=200\")\nplt.ylabel(\"Accuracy\")\nplt.plot(kappa_list,tmp_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_list\n\nimport matplotlib.pyplot as plt\nplt.title(\"Targeted L2 Carlini Wagner Attack on Kuzushiji\")\nplt.xlabel(\"Different c values keeping k=5,learning_rate=0.01,num_iters=200\")\nplt.ylabel(\"Accuracy\")\nplt.plot(options,tmp_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.utils import save_image","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Create a directory if not exists\nsample_dir = 'samples'\nif not os.path.exists(sample_dir):\n    os.makedirs(sample_dir)\n\n# Hyper-parameters\nimage_size = 784\nh_dim = 400\nz_dim = 60\nnum_epochs = 20\nbatch_size = 64\nlearning_rate = 2e-3\n\n# MNIST dataset\ndataset = torchvision.datasets.KMNIST(root='../../data',\n                                     train=True,\n                                     transform=transforms.ToTensor(),\n                                     download=True)\n\n# Data loader\ndata_loader = torch.utils.data.DataLoader(dataset=dataset,\n                                          batch_size=batch_size, \n                                          shuffle=True)\n\n\n# VAE model\nclass VAE(nn.Module):\n    def __init__(self, image_size=784, h_dim=400, z_dim=60):\n        super(VAE, self).__init__()\n        self.fc1 = nn.Linear(image_size, 500)\n        self.fc2 = nn.Linear(500, 300)\n        self.fc3 = nn.Linear(300, 150)\n        self.fc4 = nn.Linear(150, z_dim)\n        self.fc41 = nn.Linear(150, z_dim)\n        self.fc5 = nn.Linear(z_dim, 150)\n        self.fc6 = nn.Linear(150, 300)\n        self.fc7 = nn.Linear(300, 500)\n        self.fc8 = nn.Linear(500, image_size)\n        \n    def encode(self, x):\n        h = F.relu(self.fc1(x))\n        h = F.relu(self.fc2(h))\n        h = F.relu(self.fc3(h))\n        return self.fc4(h), self.fc41(h)\n    \n    def reparameterize(self, mu, log_var):\n        std = torch.exp(log_var/2)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z):\n        h = F.relu(self.fc5(z))\n        h = F.relu(self.fc6(h))\n        h = F.relu(self.fc7(h))\n        return F.sigmoid(self.fc8(h))\n    \n    def forward(self, x):\n        mu, log_var = self.encode(x)\n        z = self.reparameterize(mu, log_var)\n        x_reconst = self.decode(z)\n        return x_reconst, mu, log_var\n\nmodel = VAE().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# Start training\nfor epoch in range(num_epochs):\n    for i, (x, _) in enumerate(data_loader):\n        # Forward pass\n        x = x.to(device).view(-1, image_size)\n        x_reconst, mu, log_var = model(x)\n        \n        # Compute reconstruction loss and kl divergence\n        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n        \n        # Backprop and optimize\n        loss = reconst_loss + kl_div\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 200 == 0:\n            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}, TOTAL : {:.4f}\" \n                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item(), kl_div.item()+reconst_loss.item()))\n","execution_count":26,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n  warnings.warn(warning.format(ret))\n","name":"stderr"},{"output_type":"stream","text":"Epoch[1/20], Step [200/938], Reconst Loss: 20012.3164, KL Div: 483.3965, TOTAL : 20495.7129\nEpoch[1/20], Step [400/938], Reconst Loss: 19332.6699, KL Div: 469.8812, TOTAL : 19802.5511\nEpoch[1/20], Step [600/938], Reconst Loss: 17345.7734, KL Div: 507.4565, TOTAL : 17853.2300\nEpoch[1/20], Step [800/938], Reconst Loss: 17462.6562, KL Div: 489.5184, TOTAL : 17952.1747\nEpoch[2/20], Step [200/938], Reconst Loss: 15186.6865, KL Div: 554.5348, TOTAL : 15741.2213\nEpoch[2/20], Step [400/938], Reconst Loss: 15716.6895, KL Div: 591.3491, TOTAL : 16308.0386\nEpoch[2/20], Step [600/938], Reconst Loss: 16666.0762, KL Div: 614.4821, TOTAL : 17280.5582\nEpoch[2/20], Step [800/938], Reconst Loss: 16519.1113, KL Div: 559.4547, TOTAL : 17078.5660\nEpoch[3/20], Step [200/938], Reconst Loss: 14638.8096, KL Div: 618.8929, TOTAL : 15257.7025\nEpoch[3/20], Step [400/938], Reconst Loss: 15602.7217, KL Div: 589.5343, TOTAL : 16192.2560\nEpoch[3/20], Step [600/938], Reconst Loss: 14520.1592, KL Div: 628.1704, TOTAL : 15148.3296\nEpoch[3/20], Step [800/938], Reconst Loss: 14307.6172, KL Div: 618.1573, TOTAL : 14925.7745\nEpoch[4/20], Step [200/938], Reconst Loss: 15684.0742, KL Div: 634.8049, TOTAL : 16318.8792\nEpoch[4/20], Step [400/938], Reconst Loss: 14924.3350, KL Div: 627.7883, TOTAL : 15552.1233\nEpoch[4/20], Step [600/938], Reconst Loss: 15432.4326, KL Div: 644.5548, TOTAL : 16076.9874\nEpoch[4/20], Step [800/938], Reconst Loss: 15701.2930, KL Div: 657.0470, TOTAL : 16358.3400\nEpoch[5/20], Step [200/938], Reconst Loss: 14113.6455, KL Div: 667.2599, TOTAL : 14780.9054\nEpoch[5/20], Step [400/938], Reconst Loss: 14811.5371, KL Div: 654.3356, TOTAL : 15465.8727\nEpoch[5/20], Step [600/938], Reconst Loss: 14697.7090, KL Div: 655.2430, TOTAL : 15352.9520\nEpoch[5/20], Step [800/938], Reconst Loss: 14736.0938, KL Div: 686.2272, TOTAL : 15422.3210\nEpoch[6/20], Step [200/938], Reconst Loss: 14709.8301, KL Div: 679.1217, TOTAL : 15388.9518\nEpoch[6/20], Step [400/938], Reconst Loss: 15154.7656, KL Div: 652.4967, TOTAL : 15807.2623\nEpoch[6/20], Step [600/938], Reconst Loss: 14113.3604, KL Div: 664.9235, TOTAL : 14778.2838\nEpoch[6/20], Step [800/938], Reconst Loss: 15560.6738, KL Div: 676.6711, TOTAL : 16237.3449\nEpoch[7/20], Step [200/938], Reconst Loss: 15739.7168, KL Div: 696.1202, TOTAL : 16435.8370\nEpoch[7/20], Step [400/938], Reconst Loss: 15486.2559, KL Div: 650.0986, TOTAL : 16136.3545\nEpoch[7/20], Step [600/938], Reconst Loss: 14391.4150, KL Div: 685.1552, TOTAL : 15076.5703\nEpoch[7/20], Step [800/938], Reconst Loss: 14698.9805, KL Div: 656.0438, TOTAL : 15355.0242\nEpoch[8/20], Step [200/938], Reconst Loss: 14201.0605, KL Div: 681.6870, TOTAL : 14882.7476\nEpoch[8/20], Step [400/938], Reconst Loss: 13910.5166, KL Div: 661.8950, TOTAL : 14572.4116\nEpoch[8/20], Step [600/938], Reconst Loss: 13663.8398, KL Div: 678.6966, TOTAL : 14342.5364\nEpoch[8/20], Step [800/938], Reconst Loss: 14870.4414, KL Div: 688.7645, TOTAL : 15559.2059\nEpoch[9/20], Step [200/938], Reconst Loss: 14656.1504, KL Div: 704.2755, TOTAL : 15360.4259\nEpoch[9/20], Step [400/938], Reconst Loss: 15413.5410, KL Div: 671.6771, TOTAL : 16085.2181\nEpoch[9/20], Step [600/938], Reconst Loss: 13922.4199, KL Div: 684.5292, TOTAL : 14606.9491\nEpoch[9/20], Step [800/938], Reconst Loss: 14897.8047, KL Div: 690.9608, TOTAL : 15588.7655\nEpoch[10/20], Step [200/938], Reconst Loss: 13725.5947, KL Div: 692.4683, TOTAL : 14418.0630\nEpoch[10/20], Step [400/938], Reconst Loss: 14996.2969, KL Div: 688.3430, TOTAL : 15684.6399\nEpoch[10/20], Step [600/938], Reconst Loss: 14618.2061, KL Div: 729.8160, TOTAL : 15348.0221\nEpoch[10/20], Step [800/938], Reconst Loss: 14978.9629, KL Div: 674.7723, TOTAL : 15653.7352\nEpoch[11/20], Step [200/938], Reconst Loss: 14273.1484, KL Div: 673.4575, TOTAL : 14946.6060\nEpoch[11/20], Step [400/938], Reconst Loss: 14071.3965, KL Div: 707.8000, TOTAL : 14779.1965\nEpoch[11/20], Step [600/938], Reconst Loss: 14524.0332, KL Div: 724.2697, TOTAL : 15248.3029\nEpoch[11/20], Step [800/938], Reconst Loss: 14444.7725, KL Div: 713.6126, TOTAL : 15158.3851\nEpoch[12/20], Step [200/938], Reconst Loss: 15031.3232, KL Div: 676.9972, TOTAL : 15708.3204\nEpoch[12/20], Step [400/938], Reconst Loss: 13657.2539, KL Div: 701.9269, TOTAL : 14359.1808\nEpoch[12/20], Step [600/938], Reconst Loss: 13602.4785, KL Div: 697.8096, TOTAL : 14300.2881\nEpoch[12/20], Step [800/938], Reconst Loss: 15242.9766, KL Div: 719.4418, TOTAL : 15962.4183\nEpoch[13/20], Step [200/938], Reconst Loss: 14295.0781, KL Div: 728.1486, TOTAL : 15023.2267\nEpoch[13/20], Step [400/938], Reconst Loss: 14641.4805, KL Div: 710.5548, TOTAL : 15352.0353\nEpoch[13/20], Step [600/938], Reconst Loss: 14497.1250, KL Div: 714.2874, TOTAL : 15211.4124\nEpoch[13/20], Step [800/938], Reconst Loss: 15775.3643, KL Div: 710.5829, TOTAL : 16485.9471\nEpoch[14/20], Step [200/938], Reconst Loss: 13621.7227, KL Div: 707.2372, TOTAL : 14328.9598\nEpoch[14/20], Step [400/938], Reconst Loss: 14330.5254, KL Div: 731.6974, TOTAL : 15062.2228\nEpoch[14/20], Step [600/938], Reconst Loss: 13460.1855, KL Div: 699.1837, TOTAL : 14159.3692\nEpoch[14/20], Step [800/938], Reconst Loss: 14589.5986, KL Div: 702.4537, TOTAL : 15292.0523\nEpoch[15/20], Step [200/938], Reconst Loss: 13622.7695, KL Div: 739.9684, TOTAL : 14362.7380\nEpoch[15/20], Step [400/938], Reconst Loss: 14049.8711, KL Div: 731.1358, TOTAL : 14781.0069\nEpoch[15/20], Step [600/938], Reconst Loss: 13387.7656, KL Div: 730.9665, TOTAL : 14118.7321\nEpoch[15/20], Step [800/938], Reconst Loss: 14222.8906, KL Div: 764.6172, TOTAL : 14987.5078\nEpoch[16/20], Step [200/938], Reconst Loss: 15071.2773, KL Div: 733.0574, TOTAL : 15804.3347\nEpoch[16/20], Step [400/938], Reconst Loss: 13358.2549, KL Div: 761.2126, TOTAL : 14119.4675\nEpoch[16/20], Step [600/938], Reconst Loss: 13470.3203, KL Div: 735.6560, TOTAL : 14205.9763\nEpoch[16/20], Step [800/938], Reconst Loss: 14157.7812, KL Div: 728.7729, TOTAL : 14886.5542\nEpoch[17/20], Step [200/938], Reconst Loss: 14266.1309, KL Div: 754.6989, TOTAL : 15020.8297\nEpoch[17/20], Step [400/938], Reconst Loss: 14536.6230, KL Div: 747.0109, TOTAL : 15283.6340\nEpoch[17/20], Step [600/938], Reconst Loss: 14212.3086, KL Div: 767.8317, TOTAL : 14980.1403\nEpoch[17/20], Step [800/938], Reconst Loss: 14196.4033, KL Div: 766.6802, TOTAL : 14963.0835\nEpoch[18/20], Step [200/938], Reconst Loss: 14561.9453, KL Div: 784.5421, TOTAL : 15346.4874\nEpoch[18/20], Step [400/938], Reconst Loss: 13630.8281, KL Div: 764.4133, TOTAL : 14395.2414\nEpoch[18/20], Step [600/938], Reconst Loss: 13554.8203, KL Div: 758.4515, TOTAL : 14313.2718\nEpoch[18/20], Step [800/938], Reconst Loss: 13763.4004, KL Div: 758.3008, TOTAL : 14521.7012\nEpoch[19/20], Step [200/938], Reconst Loss: 13994.4980, KL Div: 800.2521, TOTAL : 14794.7502\nEpoch[19/20], Step [400/938], Reconst Loss: 14350.7422, KL Div: 787.9407, TOTAL : 15138.6829\nEpoch[19/20], Step [600/938], Reconst Loss: 14971.5244, KL Div: 778.1749, TOTAL : 15749.6993\nEpoch[19/20], Step [800/938], Reconst Loss: 14926.6904, KL Div: 788.6279, TOTAL : 15715.3184\nEpoch[20/20], Step [200/938], Reconst Loss: 13768.1328, KL Div: 792.0561, TOTAL : 14560.1889\nEpoch[20/20], Step [400/938], Reconst Loss: 14220.2402, KL Div: 771.8848, TOTAL : 14992.1250\nEpoch[20/20], Step [600/938], Reconst Loss: 13729.8428, KL Div: 769.1246, TOTAL : 14498.9674\nEpoch[20/20], Step [800/938], Reconst Loss: 14727.2080, KL Div: 800.8647, TOTAL : 15528.0728\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Start training\nfor epoch in range(num_epochs):\n    for i, (x, _) in enumerate(data_loader):\n        # Forward pass\n        x = x.to(device).view(-1, image_size)\n        x_reconst, mu, log_var = model(x)\n        \n        # Compute reconstruction loss and kl divergence\n        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n        \n        # Backprop and optimize\n        loss = reconst_loss + kl_div\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 200 == 0:\n            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}, TOTAL : {:.4f}\" \n                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item(), kl_div.item()+reconst_loss.item()))\n","execution_count":28,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n  warnings.warn(warning.format(ret))\n","name":"stderr"},{"output_type":"stream","text":"Epoch[1/20], Step [200/938], Reconst Loss: 13397.7920, KL Div: 788.1029, TOTAL : 14185.8949\nEpoch[1/20], Step [400/938], Reconst Loss: 13240.7705, KL Div: 797.4417, TOTAL : 14038.2122\nEpoch[1/20], Step [600/938], Reconst Loss: 14041.8320, KL Div: 784.4711, TOTAL : 14826.3031\nEpoch[1/20], Step [800/938], Reconst Loss: 13132.9678, KL Div: 777.5554, TOTAL : 13910.5231\nEpoch[2/20], Step [200/938], Reconst Loss: 14766.9189, KL Div: 805.9244, TOTAL : 15572.8434\nEpoch[2/20], Step [400/938], Reconst Loss: 14761.4062, KL Div: 776.2466, TOTAL : 15537.6529\nEpoch[2/20], Step [600/938], Reconst Loss: 13482.3477, KL Div: 761.0208, TOTAL : 14243.3685\nEpoch[2/20], Step [800/938], Reconst Loss: 15245.2344, KL Div: 814.9751, TOTAL : 16060.2095\nEpoch[3/20], Step [200/938], Reconst Loss: 12743.2148, KL Div: 801.1198, TOTAL : 13544.3347\nEpoch[3/20], Step [400/938], Reconst Loss: 13348.1191, KL Div: 833.8094, TOTAL : 14181.9286\nEpoch[3/20], Step [600/938], Reconst Loss: 13659.7676, KL Div: 820.6782, TOTAL : 14480.4458\nEpoch[3/20], Step [800/938], Reconst Loss: 13622.6172, KL Div: 794.8386, TOTAL : 14417.4558\nEpoch[4/20], Step [200/938], Reconst Loss: 14552.9639, KL Div: 801.0573, TOTAL : 15354.0212\nEpoch[4/20], Step [400/938], Reconst Loss: 12905.3359, KL Div: 809.4563, TOTAL : 13714.7922\nEpoch[4/20], Step [600/938], Reconst Loss: 14037.7188, KL Div: 780.3392, TOTAL : 14818.0580\nEpoch[4/20], Step [800/938], Reconst Loss: 14207.2793, KL Div: 774.2425, TOTAL : 14981.5218\nEpoch[5/20], Step [200/938], Reconst Loss: 13988.3711, KL Div: 787.9945, TOTAL : 14776.3656\nEpoch[5/20], Step [400/938], Reconst Loss: 13359.2402, KL Div: 784.8323, TOTAL : 14144.0725\nEpoch[5/20], Step [600/938], Reconst Loss: 13279.0137, KL Div: 816.5528, TOTAL : 14095.5665\nEpoch[5/20], Step [800/938], Reconst Loss: 13912.4590, KL Div: 798.9087, TOTAL : 14711.3677\nEpoch[6/20], Step [200/938], Reconst Loss: 14185.4912, KL Div: 813.7932, TOTAL : 14999.2844\nEpoch[6/20], Step [400/938], Reconst Loss: 12993.3145, KL Div: 823.1485, TOTAL : 13816.4630\nEpoch[6/20], Step [600/938], Reconst Loss: 13279.5762, KL Div: 812.8556, TOTAL : 14092.4318\nEpoch[6/20], Step [800/938], Reconst Loss: 13204.6504, KL Div: 834.7552, TOTAL : 14039.4056\nEpoch[7/20], Step [200/938], Reconst Loss: 14406.6895, KL Div: 786.6968, TOTAL : 15193.3863\nEpoch[7/20], Step [400/938], Reconst Loss: 14114.2695, KL Div: 807.0490, TOTAL : 14921.3185\nEpoch[7/20], Step [600/938], Reconst Loss: 14178.3750, KL Div: 796.8286, TOTAL : 14975.2036\nEpoch[7/20], Step [800/938], Reconst Loss: 14573.3682, KL Div: 815.8694, TOTAL : 15389.2375\nEpoch[8/20], Step [200/938], Reconst Loss: 14048.8711, KL Div: 796.5614, TOTAL : 14845.4325\nEpoch[8/20], Step [400/938], Reconst Loss: 14451.9512, KL Div: 816.2947, TOTAL : 15268.2459\nEpoch[8/20], Step [600/938], Reconst Loss: 14351.5049, KL Div: 844.0547, TOTAL : 15195.5596\nEpoch[8/20], Step [800/938], Reconst Loss: 14591.5801, KL Div: 814.5219, TOTAL : 15406.1019\nEpoch[9/20], Step [200/938], Reconst Loss: 14099.7939, KL Div: 818.6975, TOTAL : 14918.4915\nEpoch[9/20], Step [400/938], Reconst Loss: 13798.6680, KL Div: 790.5010, TOTAL : 14589.1689\nEpoch[9/20], Step [600/938], Reconst Loss: 14237.3223, KL Div: 806.9684, TOTAL : 15044.2906\nEpoch[9/20], Step [800/938], Reconst Loss: 13314.5195, KL Div: 799.5479, TOTAL : 14114.0674\nEpoch[10/20], Step [200/938], Reconst Loss: 13253.0684, KL Div: 809.4520, TOTAL : 14062.5204\nEpoch[10/20], Step [400/938], Reconst Loss: 13086.3408, KL Div: 844.4780, TOTAL : 13930.8188\nEpoch[10/20], Step [600/938], Reconst Loss: 15242.9307, KL Div: 810.6157, TOTAL : 16053.5464\nEpoch[10/20], Step [800/938], Reconst Loss: 14763.7578, KL Div: 819.5204, TOTAL : 15583.2782\nEpoch[11/20], Step [200/938], Reconst Loss: 14318.5371, KL Div: 815.6345, TOTAL : 15134.1716\nEpoch[11/20], Step [400/938], Reconst Loss: 13455.1348, KL Div: 810.3597, TOTAL : 14265.4944\nEpoch[11/20], Step [600/938], Reconst Loss: 14030.9297, KL Div: 840.2051, TOTAL : 14871.1348\nEpoch[11/20], Step [800/938], Reconst Loss: 13474.0938, KL Div: 818.0060, TOTAL : 14292.0997\nEpoch[12/20], Step [200/938], Reconst Loss: 13961.0508, KL Div: 824.2670, TOTAL : 14785.3178\nEpoch[12/20], Step [400/938], Reconst Loss: 14846.6367, KL Div: 831.3119, TOTAL : 15677.9486\nEpoch[12/20], Step [600/938], Reconst Loss: 14031.9131, KL Div: 789.7626, TOTAL : 14821.6757\nEpoch[12/20], Step [800/938], Reconst Loss: 13380.0957, KL Div: 798.1205, TOTAL : 14178.2162\nEpoch[13/20], Step [200/938], Reconst Loss: 13486.7109, KL Div: 808.4898, TOTAL : 14295.2007\nEpoch[13/20], Step [400/938], Reconst Loss: 13048.5137, KL Div: 844.1199, TOTAL : 13892.6335\nEpoch[13/20], Step [600/938], Reconst Loss: 13855.2871, KL Div: 833.4558, TOTAL : 14688.7429\nEpoch[13/20], Step [800/938], Reconst Loss: 13709.9160, KL Div: 788.4236, TOTAL : 14498.3397\nEpoch[14/20], Step [200/938], Reconst Loss: 13577.3281, KL Div: 808.4037, TOTAL : 14385.7318\nEpoch[14/20], Step [400/938], Reconst Loss: 13976.3730, KL Div: 828.7269, TOTAL : 14805.1000\nEpoch[14/20], Step [600/938], Reconst Loss: 13286.7441, KL Div: 797.3083, TOTAL : 14084.0525\nEpoch[14/20], Step [800/938], Reconst Loss: 13560.5371, KL Div: 842.7764, TOTAL : 14403.3135\nEpoch[15/20], Step [200/938], Reconst Loss: 13130.2949, KL Div: 808.7760, TOTAL : 13939.0709\nEpoch[15/20], Step [400/938], Reconst Loss: 13996.7344, KL Div: 812.8192, TOTAL : 14809.5535\nEpoch[15/20], Step [600/938], Reconst Loss: 13171.0605, KL Div: 856.0352, TOTAL : 14027.0957\nEpoch[15/20], Step [800/938], Reconst Loss: 14300.2559, KL Div: 813.5165, TOTAL : 15113.7723\nEpoch[16/20], Step [200/938], Reconst Loss: 13133.0879, KL Div: 814.0980, TOTAL : 13947.1859\nEpoch[16/20], Step [400/938], Reconst Loss: 13629.4668, KL Div: 822.1287, TOTAL : 14451.5955\nEpoch[16/20], Step [600/938], Reconst Loss: 12976.6465, KL Div: 793.6085, TOTAL : 13770.2549\nEpoch[16/20], Step [800/938], Reconst Loss: 13625.9824, KL Div: 799.9651, TOTAL : 14425.9475\nEpoch[17/20], Step [200/938], Reconst Loss: 13073.4482, KL Div: 821.5854, TOTAL : 13895.0337\nEpoch[17/20], Step [400/938], Reconst Loss: 12308.7285, KL Div: 817.5309, TOTAL : 13126.2594\nEpoch[17/20], Step [600/938], Reconst Loss: 13433.3750, KL Div: 831.4128, TOTAL : 14264.7878\nEpoch[17/20], Step [800/938], Reconst Loss: 13580.4648, KL Div: 821.0177, TOTAL : 14401.4825\nEpoch[18/20], Step [200/938], Reconst Loss: 14063.8740, KL Div: 815.7104, TOTAL : 14879.5845\nEpoch[18/20], Step [400/938], Reconst Loss: 12876.5586, KL Div: 857.6423, TOTAL : 13734.2009\nEpoch[18/20], Step [600/938], Reconst Loss: 13479.1553, KL Div: 819.2465, TOTAL : 14298.4017\nEpoch[18/20], Step [800/938], Reconst Loss: 14410.5488, KL Div: 816.9758, TOTAL : 15227.5247\nEpoch[19/20], Step [200/938], Reconst Loss: 13638.0664, KL Div: 805.8256, TOTAL : 14443.8920\nEpoch[19/20], Step [400/938], Reconst Loss: 13619.0186, KL Div: 842.3754, TOTAL : 14461.3939\nEpoch[19/20], Step [600/938], Reconst Loss: 13762.8252, KL Div: 823.3093, TOTAL : 14586.1345\nEpoch[19/20], Step [800/938], Reconst Loss: 12740.0635, KL Div: 797.6305, TOTAL : 13537.6940\nEpoch[20/20], Step [200/938], Reconst Loss: 13777.5078, KL Div: 860.9420, TOTAL : 14638.4498\nEpoch[20/20], Step [400/938], Reconst Loss: 13084.7500, KL Div: 847.2235, TOTAL : 13931.9735\nEpoch[20/20], Step [600/938], Reconst Loss: 13350.5254, KL Div: 843.0580, TOTAL : 14193.5834\nEpoch[20/20], Step [800/938], Reconst Loss: 11890.9775, KL Div: 828.0820, TOTAL : 12719.0596\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"l[0][0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Result for Defense on CW Attack using VAE"},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    \n    correct=0\n    total=0\n    for attacked,trueimages,labels in l:\n        \n        attacked=trueimages.reshape(-1,1,28,28).to(device)\n        labels=labels.to(device)\n        \n        vae_input = attacked.view(-1, image_size)\n        attacked_reconstructed, mu, log_var = model(vae_input)\n        attacked_reconstructed=attacked_reconstructed.view(-1,1,28,28)\n        outputs=my_model(attacked_reconstructed)[0]\n        \n        _,predicted=torch.max(outputs.data,1)\n        total+=labels.size(0)\n        correct+=(predicted==labels).sum().item()\n        print('Accuracy of the network on the attacked images so far: {} %'.format(100 * correct / total))\n        \n    print('Final Accuracy of the network on the attacked images: {} %'.format(100 * correct / total))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Result for Defense against Targeted FGSM Attack using VAE"},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    \n    correct=0\n    total=0\n    for attacked,trueimages,labels in l_tfgsm:\n        \n        attacked=trueimages.reshape(-1,1,28,28).to(device)\n        labels=labels.to(device)\n        \n        vae_input = attacked.view(-1, image_size)\n        attacked_reconstructed, mu, log_var = model(vae_input)\n        attacked_reconstructed=attacked_reconstructed.view(-1,1,28,28)\n        outputs=my_model(attacked_reconstructed)[0]\n        \n        _,predicted=torch.max(outputs.data,1)\n        total+=labels.size(0)\n        correct+=(predicted==labels).sum().item()\n        print('Accuracy of the network on the attacked images so far: {} %'.format(100 * correct / total))\n        \n    print('Final Accuracy of the network on the attacked images: {} %'.format(100 * correct / total))\n    ","execution_count":27,"outputs":[{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 78.0 %\nAccuracy of the network on the attacked images so far: 76.0 %\nAccuracy of the network on the attacked images so far: 74.33333333333333 %\nAccuracy of the network on the attacked images so far: 72.75 %\nAccuracy of the network on the attacked images so far: 72.2 %\nAccuracy of the network on the attacked images so far: 72.5 %\nAccuracy of the network on the attacked images so far: 72.42857142857143 %\nAccuracy of the network on the attacked images so far: 71.375 %\nAccuracy of the network on the attacked images so far: 71.22222222222223 %\nAccuracy of the network on the attacked images so far: 71.0 %\nAccuracy of the network on the attacked images so far: 71.0909090909091 %\nAccuracy of the network on the attacked images so far: 71.16666666666667 %\nAccuracy of the network on the attacked images so far: 71.23076923076923 %\nAccuracy of the network on the attacked images so far: 71.21428571428571 %\nAccuracy of the network on the attacked images so far: 71.06666666666666 %\nAccuracy of the network on the attacked images so far: 71.375 %\nAccuracy of the network on the attacked images so far: 71.29411764705883 %\nAccuracy of the network on the attacked images so far: 71.16666666666667 %\nAccuracy of the network on the attacked images so far: 71.15789473684211 %\nAccuracy of the network on the attacked images so far: 71.05 %\nAccuracy of the network on the attacked images so far: 70.71428571428571 %\nAccuracy of the network on the attacked images so far: 70.72727272727273 %\nAccuracy of the network on the attacked images so far: 70.82608695652173 %\nAccuracy of the network on the attacked images so far: 71.20833333333333 %\nAccuracy of the network on the attacked images so far: 71.08 %\nAccuracy of the network on the attacked images so far: 71.03846153846153 %\nAccuracy of the network on the attacked images so far: 71.18518518518519 %\nAccuracy of the network on the attacked images so far: 70.85714285714286 %\nAccuracy of the network on the attacked images so far: 70.72413793103448 %\nAccuracy of the network on the attacked images so far: 70.9 %\nAccuracy of the network on the attacked images so far: 70.96774193548387 %\nAccuracy of the network on the attacked images so far: 71.25 %\nAccuracy of the network on the attacked images so far: 71.33333333333333 %\nAccuracy of the network on the attacked images so far: 71.38235294117646 %\nAccuracy of the network on the attacked images so far: 71.45714285714286 %\nAccuracy of the network on the attacked images so far: 71.52777777777777 %\nAccuracy of the network on the attacked images so far: 71.43243243243244 %\nAccuracy of the network on the attacked images so far: 71.26315789473684 %\nAccuracy of the network on the attacked images so far: 71.28205128205128 %\nAccuracy of the network on the attacked images so far: 71.325 %\nAccuracy of the network on the attacked images so far: 71.4390243902439 %\nAccuracy of the network on the attacked images so far: 71.42857142857143 %\nAccuracy of the network on the attacked images so far: 71.46511627906976 %\nAccuracy of the network on the attacked images so far: 71.56818181818181 %\nAccuracy of the network on the attacked images so far: 71.42222222222222 %\nAccuracy of the network on the attacked images so far: 71.34782608695652 %\nAccuracy of the network on the attacked images so far: 71.2127659574468 %\nAccuracy of the network on the attacked images so far: 71.22916666666667 %\nAccuracy of the network on the attacked images so far: 71.3265306122449 %\nAccuracy of the network on the attacked images so far: 71.34 %\nAccuracy of the network on the attacked images so far: 71.37254901960785 %\nAccuracy of the network on the attacked images so far: 71.40384615384616 %\nAccuracy of the network on the attacked images so far: 71.28301886792453 %\nAccuracy of the network on the attacked images so far: 71.25925925925925 %\nAccuracy of the network on the attacked images so far: 71.32727272727273 %\nAccuracy of the network on the attacked images so far: 71.39285714285714 %\nAccuracy of the network on the attacked images so far: 71.36842105263158 %\nAccuracy of the network on the attacked images so far: 71.3103448275862 %\nAccuracy of the network on the attacked images so far: 71.1864406779661 %\nAccuracy of the network on the attacked images so far: 71.11666666666666 %\nAccuracy of the network on the attacked images so far: 71.14754098360656 %\nAccuracy of the network on the attacked images so far: 71.01612903225806 %\nAccuracy of the network on the attacked images so far: 71.04761904761905 %\nAccuracy of the network on the attacked images so far: 71.125 %\nAccuracy of the network on the attacked images so far: 71.12307692307692 %\nAccuracy of the network on the attacked images so far: 71.03030303030303 %\nAccuracy of the network on the attacked images so far: 71.02985074626865 %\nAccuracy of the network on the attacked images so far: 71.07352941176471 %\nAccuracy of the network on the attacked images so far: 71.08695652173913 %\nAccuracy of the network on the attacked images so far: 71.08571428571429 %\nAccuracy of the network on the attacked images so far: 71.15492957746478 %\nAccuracy of the network on the attacked images so far: 71.125 %\nAccuracy of the network on the attacked images so far: 71.12328767123287 %\nAccuracy of the network on the attacked images so far: 71.20270270270271 %\nAccuracy of the network on the attacked images so far: 71.18666666666667 %\nAccuracy of the network on the attacked images so far: 71.11842105263158 %\nAccuracy of the network on the attacked images so far: 71.07792207792208 %\nAccuracy of the network on the attacked images so far: 71.06410256410257 %\nAccuracy of the network on the attacked images so far: 70.9493670886076 %\nAccuracy of the network on the attacked images so far: 70.9625 %\nAccuracy of the network on the attacked images so far: 70.96296296296296 %\nAccuracy of the network on the attacked images so far: 71.0609756097561 %\nAccuracy of the network on the attacked images so far: 71.09638554216868 %\nAccuracy of the network on the attacked images so far: 71.10714285714286 %\nAccuracy of the network on the attacked images so far: 71.11764705882354 %\nAccuracy of the network on the attacked images so far: 71.09302325581395 %\nAccuracy of the network on the attacked images so far: 71.04597701149426 %\nAccuracy of the network on the attacked images so far: 70.97727272727273 %\nAccuracy of the network on the attacked images so far: 71.02247191011236 %\nAccuracy of the network on the attacked images so far: 71.1 %\nAccuracy of the network on the attacked images so far: 71.0989010989011 %\nAccuracy of the network on the attacked images so far: 71.08695652173913 %\nAccuracy of the network on the attacked images so far: 71.12903225806451 %\nAccuracy of the network on the attacked images so far: 71.1063829787234 %\nAccuracy of the network on the attacked images so far: 71.14736842105263 %\nAccuracy of the network on the attacked images so far: 71.11458333333333 %\nAccuracy of the network on the attacked images so far: 71.04123711340206 %\nAccuracy of the network on the attacked images so far: 71.08163265306122 %\nAccuracy of the network on the attacked images so far: 71.12121212121212 %\nAccuracy of the network on the attacked images so far: 71.13 %\nFinal Accuracy of the network on the attacked images: 71.13 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"# Defense VAE using KNN methodology"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# l contains values for the CW attack\n# l_tgsm contains the value for the tfgsm attack\n\nfrom sklearn.neighbors import NearestNeighbors\nimport matplotlib.pyplot as plt\n\nN=4000 #generating N random images from Z space\n\nwith torch.no_grad():\n        # Save the sampled images\n    z = torch.randn(N, z_dim).to(device)\n    out = model.decode(z)  #generation of N images\n    #print(out.shape)\n    output= out.view(-1,1,28,28)\n    \nsamples=out.cpu().numpy()\n#print(numpy_out.shape)\nneigh=NearestNeighbors(n_neighbors=1)\nneigh.fit(samples)","execution_count":53,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","name":"stderr"},{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n         metric_params=None, n_jobs=None, n_neighbors=1, p=2, radius=1.0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct=0\ntotal=0\n\nfor attacked,trueimages,labels in l_pgd:\n    #implementing the K-NN on the attacked\n    #print(attacked.shape)\n    #print(trueimages.shape)\n    #print(labels.shape)\n    \n    labels=labels.to(device)\n    temp=attacked.view(-1,image_size).detach()\n    numpy_attacked=temp.cpu().numpy()\n    result=neigh.kneighbors(numpy_attacked)\n    #result[1] is a numpy array containing the index of the closest image in the sample space\n    \n    index=list(result[1].flatten())\n    #print(index)\n    \n    ClosestImage=out[index,:]\n    input_to_classifier=ClosestImage.reshape(-1,1,28,28).to(device)\n    #print(input_to_classifier.shape)\n    output=my_model(input_to_classifier)[0]\n    _,predicted=torch.max(outputs.data,1)\n    total+=labels.size(0)\n    correct+=(predicted==labels).sum().item()\n    print('Accuracy of the network on the attacked images so far: {} %'.format(100 * correct / total))\n        \nprint('Final Accuracy of the network on the attacked images: {} %'.format(100 * correct / total))","execution_count":69,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 14.0 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 10.5 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 10.0 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.75 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 10.4 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 10.166666666666666 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.428571428571429 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 10.0 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.444444444444445 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.8 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.818181818181818 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.75 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.846153846153847 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.428571428571429 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.266666666666667 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.1875 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.176470588235293 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.38888888888889 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.368421052631579 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.65 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.571428571428571 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.409090909090908 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.304347826086957 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.416666666666666 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.56 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.461538461538462 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.407407407407407 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.5 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.482758620689655 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.433333333333334 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.548387096774194 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.5625 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.575757575757576 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.558823529411764 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.485714285714286 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.472222222222221 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.513513513513514 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.578947368421053 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.820512820512821 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.875 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 10.0 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.976190476190476 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.976744186046512 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.931818181818182 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.933333333333334 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.869565217391305 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.787234042553191 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.75 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.795918367346939 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.7 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.72549019607843 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.653846153846153 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.660377358490566 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.648148148148149 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.636363636363637 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.660714285714286 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.666666666666666 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.689655172413794 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.728813559322035 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.733333333333333 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.737704918032787 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.693548387096774 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.65079365079365 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.59375 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.538461538461538 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.590909090909092 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.552238805970148 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.544117647058824 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.507246376811594 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.442857142857143 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.535211267605634 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.541666666666666 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.561643835616438 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.608108108108109 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.68 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.657894736842104 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.662337662337663 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.64102564102564 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.594936708860759 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.5875 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.580246913580247 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.609756097560975 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.626506024096386 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.607142857142858 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.6 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.616279069767442 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.620689655172415 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.613636363636363 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.617977528089888 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.6 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.615384615384615 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.619565217391305 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.602150537634408 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.606382978723405 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.589473684210526 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.59375 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.628865979381443 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.642857142857142 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the attacked images so far: 9.626262626262626 %\nAccuracy of the network on the attacked images so far: 10.44 %\nFinal Accuracy of the network on the attacked images: 10.44 %\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  input = module(input)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VAE Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    # Save the sampled images\n    z = torch.randn(batch_size, z_dim).to(device)\n    out = model.decode(z).view(-1, 1, 28, 28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    # Save the sampled images\n    z = torch.randn(batch_size, z_dim).to(device)\n    out = model.decode(z).view(-1, 1, 28, 28)\n    \nprint(out.shape)\nout = out.reshape(-1, 28,28).cpu().numpy()\nprint(out.shape)\nimport matplotlib.pyplot as plt\nfrom pylab import * \nrangee = 3\nfor k in range(1, rangee):\n    subplot(2, rangee, k)\n    plt.axis('off')\n    imshow(out[k], cmap='Greys')\n    subplot(2, rangee, k+rangee)\n    imshow(out[k+rangee], cmap='Greys')\n    plt.axis('off')   ","execution_count":42,"outputs":[{"output_type":"stream","text":"torch.Size([64, 1, 28, 28])\n(64, 28, 28)\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 4 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(num_epochs):\n    for i, (x, _) in enumerate(data_loader):\n        # Forward pass\n        x = x.to(device).view(-1, image_size)\n        x_reconst, mu, log_var = model(x)\n        \n        # Compute reconstruction loss and kl divergence\n        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n        \n        # Backprop and optimize\n        loss = reconst_loss + 0.8*kl_div\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 200 == 0:\n            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}, TOTAL : {:.4f}\" \n                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item(), kl_div.item()+reconst_loss.item()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Following are just snippet tests,they don't mean anything as such\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"im,_=l[0]\nim=im.data.cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"old_im,_=actual[0]\nold_im=old_im.data.cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im=im.reshape(100,28,28)\nold_im=old_im.reshape(100,28,28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(old_im[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(im[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#these ae just snippet tests they don't mean anything now\nsubplot(1,2,1)\ntitle('adversarial example')\nimshow(im[2],cmap='gray')\nsubplot(1,2,2)\ntitle('actual sample')\nimshow(old_im[2],cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image1=torch.from_numpy(im[1])\nimg_t1=image1.reshape(-1,1,28,28).to(device)\noutputs=my_model(img_t1)\n_,predicted=torch.max(outputs.data,1)\nprint(predicted)\n\nimage2=torch.from_numpy(old_im[1])\nimg_t2=image2.reshape(-1,1,28,28).to(device)\noutputs=my_model(img_t2)\n_,predicted=torch.max(outputs.data,1)\nprint(predicted)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training a GAN **\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"g_input_size=10\ng_hidden_size=5\ng_output_size=\n\nd_input_size=\nd_hidden_size=10\nd_output_size=1\nminibatch_size=d_input_size \n\ngenerator_activation_function=torch.tanh\ndiscriminator_activation_function=torch.sigmoid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_generator_input_sampler():\n    return lambda n: torch.Tensor(np.random.normal(0,1,(g_input_size,1)))  #whatever is the size of the random input noise here 50*1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self,input_size,hidden_size,output_size,f):\n        super(Generator,self).__init__()\n        self.map1=nn.Linear(input_size,hidden_size)\n        self.map2=nn.Linear(hidden_size,hidden_size)\n        self.map3=nn.Linear(hidden_size,output_size)\n        self.f=f\n    def forward(self,x):\n        x=self.map1(x)\n        x=self.f(x)\n        x=self.map2(x)\n        x=self.f(x)\n        x=self.map3(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Discriminator(nn.Module):\n    def __init__(self,input_size,hidden_size,output_size,f):\n        super(Discriminator,self).__init__()\n        self.map1=nn.Linear(input_size,hidden_size)\n        self.map2=nn.Linear(hidden_size,hidden_size)\n        self.map3=nn.Linear(hidden_size,output_size)\n        self.f=f\n    def forward(self,x):\n        x=self.f(self.map1(x))\n        x=self.f(self.map2(x))\n        x=self.f(self.map3(x))\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G=Generator(input_size=g_input_size,\n           hidden_size=g_hidden_size,\n           output_size=g_output_size,\n           f=generator_activation_function)\n\nD=Discriminator(input_size=d_input_size,\n           hidden_size=d_hidden_size,\n           output_size=d_output_size,\n           f=discriminator_activation_function)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Number_epochs=50\nD_steps=5\n\nfor epoch in range(Number_epochs):\n    for d_index in range(D_steps):\n        #train D on real+fake\n        D\n        ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}