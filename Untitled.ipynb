{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ecb87e63f352>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m# Load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[0mcifar10\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "prefix = 'test'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(prefix):\n",
    "    os.makedirs(prefix)\n",
    "\n",
    "# Define modal\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(100 + 10, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024 + 10, 128 * 8 * 8)\n",
    "        self.bn2 = nn.BatchNorm1d(128 * 8 * 8)\n",
    "        self.cvt1 = nn.ConvTranspose2d(128 + 10, 64, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.cvt2 = nn.ConvTranspose2d(64 + 10, 3, 4, 2, 1)\n",
    "    def forward(self, z, label):\n",
    "        x = F.relu(self.bn1(self.fc1(torch.cat([z, label], 1))))\n",
    "        x = F.relu(self.bn2(self.fc2(torch.cat([x, label], 1))))\n",
    "        label = label.view(-1, 10, 1, 1)\n",
    "        x = F.relu(self.bn3(self.cvt1(torch.cat([x.view(-1, 128, 8, 8), label.expand(x.size(0), 10, 8, 8)], 1))))\n",
    "        return F.sigmoid(self.cvt2(torch.cat([x, label.expand(x.size(0), 10, 16, 16)], 1)))\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(3 + 10, 64, 4, 2, 1)\n",
    "        self.cv2 = nn.Conv2d(64 + 10, 128, 4, 2, 1)\n",
    "        self.bm1 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8 + 10, 1024)\n",
    "        self.bm2 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024 + 10, 1)\n",
    "    def forward(self, x, label):\n",
    "        label_expand = label.view(-1, 10, 1, 1)\n",
    "        x = F.leaky_relu(self.cv1(torch.cat([x, label_expand.expand(x.size(0), 10, 32, 32)], 1)))\n",
    "        x = F.leaky_relu(self.bm1(self.cv2(torch.cat([x, label_expand.expand(x.size(0), 10, 16, 16)], 1))))\n",
    "        x = F.leaky_relu(self.bm2(self.fc1(torch.cat([x.view(-1, 128 * 8 * 8), label], 1))))\n",
    "        return F.sigmoid(self.fc2(torch.cat([x, label], 1)))\n",
    "\n",
    "# Implement modal\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "lr = 1e-4\n",
    "cuda = False\n",
    "\n",
    "G, D = Generator(), Discriminator()\n",
    "if cuda:\n",
    "    G, D = G.cuda(), D.cuda()\n",
    "G_optim, D_optim = optim.Adam(G.parameters(), lr = lr), optim.Adam(D.parameters(), lr = lr)\n",
    "\n",
    "# Load data\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "cifar10 = datasets.CIFAR10('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "images = torch.stack([cifar10[i][0] for i in range(len(cifar10))])\n",
    "orig_labels = torch.LongTensor([cifar10[i][1] for i in range(len(cifar10))])\n",
    "labels = torch.zeros(images.size(0), 10).scatter_(1, orig_labels.view(-1, 1), 1)\n",
    "if cuda:\n",
    "    images, orig_labels, labels = images.cuda(), orig_labels.cuda(), labels.cuda()\n",
    "\n",
    "# Load and save modal\n",
    "def load_state():\n",
    "    if os.path.exists(prefix + '/checkpoint/G.data'):\n",
    "        G.load_state_dict(torch.load(prefix + '/checkpoint/G.data'))\n",
    "    if os.path.exists(prefix + '/checkpoint/D.data'):\n",
    "        D.load_state_dict(torch.load(prefix + '/checkpoint/D.data'))\n",
    "    if os.path.exists(prefix + '/checkpoint/G_optim.data'):\n",
    "        G_optim.load_state_dict(torch.load(prefix + '/checkpoint/G_optim.data'))\n",
    "    if os.path.exists(prefix + '/checkpoint/D_optim.data'):\n",
    "        D_optim.load_state_dict(torch.load(prefix + '/checkpoint/D_optim.data'))\n",
    "    begin_epoch = 0\n",
    "    if os.path.exists(prefix + '/checkpoint/epoch.data'):\n",
    "        begin_epoch = torch.load(prefix + '/checkpoint/epoch.data')\n",
    "    return begin_epoch\n",
    "\n",
    "def save_state(epoch):\n",
    "    if not os.path.exists(prefix + '/checkpoint'):\n",
    "        os.makedirs(prefix + '/checkpoint')\n",
    "    torch.save(G.state_dict(), prefix + '/checkpoint/G.data')\n",
    "    torch.save(D.state_dict(), prefix + '/checkpoint/D.data')\n",
    "    torch.save(G_optim.state_dict(), prefix + '/checkpoint/G_optim.data')\n",
    "    torch.save(D_optim.state_dict(), prefix + '/checkpoint/D_optim.data')\n",
    "    torch.save(epoch, prefix + '/checkpoint/epoch.data')\n",
    "\n",
    "# Test\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "def plt_images(images, rows, cols):\n",
    "    fig = plt.figure(figsize=(cols,rows))\n",
    "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.05, hspace=0.05)\n",
    "    for i, x in enumerate(images[:cols * rows]):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.rollaxis(x, 0, 3), norm=colors.NoNorm())\n",
    "    return fig\n",
    "\n",
    "plt_labels = Variable(torch.zeros(100, 10).scatter_(1, torch.LongTensor([[i]*10 for i in range(10)]).view(-1, 1), 1), volatile = True)\n",
    "plt_z = Variable(torch.randn(100, 100), volatile = True)\n",
    "if cuda:\n",
    "    plt_labels, plt_z = plt_labels.cuda(), plt_z.cuda()\n",
    "\n",
    "def plt_gen_with_random_noise(index):\n",
    "    z = Variable(torch.randn(100, 100), volatile = True)\n",
    "    if cuda:\n",
    "        z = z.cuda()\n",
    "    fig = plt_images(G(z, plt_labels).data.cpu().numpy(), 10, 10)\n",
    "    if not os.path.exists(prefix + '/plt_random'):\n",
    "        os.makedirs(prefix + '/plt_random')\n",
    "    fig.savefig(prefix + '/plt_random/%s.png' % str(index).zfill(5))\n",
    "    plt.close(fig)\n",
    "\n",
    "def plt_gen_with_fixed_noise(index):\n",
    "    fig = plt_images(G(plt_z, plt_labels).data.cpu().numpy(), 10, 10)\n",
    "    if not os.path.exists(prefix + '/plt_fixed'):\n",
    "        os.makedirs(prefix + '/plt_fixed')\n",
    "    fig.savefig(prefix + '/plt_fixed/%s.png' % str(index).zfill(5))\n",
    "    plt.close(fig)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "n_tsne_sample = 1000\n",
    "\n",
    "def plt_tsne(index):\n",
    "    indices = torch.from_numpy(np.random.randint(0, images.size(0), n_tsne_sample))\n",
    "    if cuda:\n",
    "        indices = indices.cuda()\n",
    "    label, z = Variable(labels[indices], volatile = True), Variable(torch.randn(n_tsne_sample, 100), volatile = True)\n",
    "    if cuda:\n",
    "        z = z.cuda()\n",
    "    source, target = images[indices].cpu().view(n_tsne_sample, 3 * 32 * 32).numpy(), G(z, label).data.cpu().view(n_tsne_sample, 3 * 32 * 32).numpy()\n",
    "    model = TSNE(n_components=2)\n",
    "    output = model.fit_transform(np.vstack([source, target]))\n",
    "    source, target = output[:source.shape[0], :], output[source.shape[0]:, :]\n",
    "    label = orig_labels[indices].cpu().numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.05, hspace=0.05)\n",
    "    src = fig.add_subplot(1, 2, 1)\n",
    "    tar = fig.add_subplot(1, 2, 2)\n",
    "    src.scatter(source[:, 0], source[:, 1], s=15, c=label, cmap='plasma', edgecolors='none', marker='o')\n",
    "    tar.scatter(target[:, 0], target[:, 1], s=15, c=label, cmap='plasma', edgecolors='none', marker='o')\n",
    "    src.axis('off')\n",
    "    tar.axis('off')\n",
    "    if not os.path.exists(prefix + '/plt_tsne'):\n",
    "        os.makedirs(prefix + '/plt_tsne')\n",
    "    plt.savefig(prefix + '/plt_tsne/%s.png' % str(index).zfill(5))\n",
    "    plt.close(fig)\n",
    "\n",
    "def test(index):\n",
    "    plt_gen_with_random_noise(index)\n",
    "    plt_gen_with_fixed_noise(index)\n",
    "    plt_tsne(index)\n",
    "\n",
    "# Train\n",
    "\n",
    "n_epoch = 20000\n",
    "batch_size = 128\n",
    "log_interval = 1\n",
    "plot_interval = 100\n",
    "save_interval = 100\n",
    "\n",
    "def train():\n",
    "    G.train()\n",
    "    D.train()\n",
    "    zeros = Variable(torch.zeros(batch_size, 1))\n",
    "    ones = Variable(torch.ones(batch_size, 1))\n",
    "    if cuda:\n",
    "        zeros, ones = zeros.cuda(), ones.cuda()\n",
    "    with open(prefix + '/log.txt', 'a') as log:\n",
    "        for i in range(load_state(), n_epoch):\n",
    "            for _ in range(5):\n",
    "                G.zero_grad()\n",
    "                D.zero_grad()\n",
    "                indices = torch.from_numpy(np.random.randint(0, images.size(0), batch_size))\n",
    "                if cuda:\n",
    "                    indices = indices.cuda()\n",
    "                realx, label, z = Variable(images[indices]), Variable(labels[indices]), Variable(torch.randn(batch_size, 100))\n",
    "                if cuda:\n",
    "                    z = z.cuda()\n",
    "                fakex = G(z, label)\n",
    "                realy, fakey = D(realx, label), D(fakex, label)\n",
    "                D_loss = F.binary_cross_entropy(realy, ones) + F.binary_cross_entropy(fakey, zeros)\n",
    "                D_loss.backward()\n",
    "                D_optim.step()\n",
    "            G.zero_grad()\n",
    "            D.zero_grad()\n",
    "            label = Variable(torch.zeros(batch_size, 10).scatter_(1, torch.from_numpy(np.random.randint(0, 10, batch_size)).view(-1, 1), 1))\n",
    "            z = Variable(torch.randn(batch_size, 100))\n",
    "            if cuda:\n",
    "                label, z = label.cuda(), z.cuda()\n",
    "            G_loss = F.binary_cross_entropy(D(G(z, label), label), ones)\n",
    "            G_loss.backward()\n",
    "            G_optim.step()\n",
    "            if i % log_interval == 0:\n",
    "                info = 'Epoch: %d; D_loss: %s; G_loss: %s' % (i, D_loss.data[0], G_loss.data[0])\n",
    "                print(info)\n",
    "                log.write(info + '\\n')\n",
    "            if i % plot_interval == 0:\n",
    "                G.eval()\n",
    "                D.eval()\n",
    "                test(i // plot_interval)\n",
    "                G.train()\n",
    "                D.train()\n",
    "            if i % save_interval == 0:\n",
    "                save_state(i)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
